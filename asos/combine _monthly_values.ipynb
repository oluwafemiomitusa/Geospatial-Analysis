{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "year = 2022\n",
    "\n",
    "# Get a list of all files in the current directory that start with 'station' and end with '.csv'\n",
    "data_files = glob.glob(f'{year}/station*.csv')\n",
    "\n",
    "# Define a function to process a season's data\n",
    "def process_season(data_files, season_name, months):\n",
    "    # Initialize an empty DataFrame to store all data for the season\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Loop over each data file\n",
    "    for file in data_files:\n",
    "        # Load the data, convert 'DATE' column to datetime format, and subset for the season's months\n",
    "        df = pd.read_csv(file, parse_dates=['DATE'])\n",
    "        df_season = df[df['DATE'].dt.month.isin(months)]\n",
    "\n",
    "        # Create 'DATE' and 'TIME' columns, and drop unnecessary columns\n",
    "        df_season = df_season.drop(['VIS', 'HEIGHT_AGL'], axis=1)\n",
    "\n",
    "        # Append this station's data for the season to the overall DataFrame\n",
    "        all_data = pd.concat([all_data, df_season])\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Process the data for each season and save to a CSV file\n",
    "seasons = {\n",
    "    'Spring': [3, 4, 5],  # March, April, May\n",
    "    'Summer': [6, 7, 8]   # June, July, August\n",
    "}\n",
    "\n",
    "for season_name, months in seasons.items():\n",
    "    all_data = process_season(data_files, season_name, months)\n",
    "    all_data.to_csv(f\"{season_name}_2022_atmospheric.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for .\\Spring_2022_atmospheric.csv saved to Spring_2022_atmospheric_atmospheric_clean.csv\n",
      "Results for .\\Summer_2022_atmospheric.csv saved to Summer_2022_atmospheric_atmospheric_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# List all the CSV files in a folder (you may need to change the file path)\n",
    "file_path = \"./*.csv\"\n",
    "csv_files = glob.glob(file_path)\n",
    "\n",
    "# Process each CSV file separately\n",
    "for file in csv_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # Read CSV data into a DataFrame\n",
    "    df = pd.read_csv(StringIO(data), parse_dates=['DATE'])\n",
    "    \n",
    "    # Modify DATE values to start from 00:00:00 and end in 00:23:59\n",
    "    df['DATE'] = df['DATE'].dt.floor('H')\n",
    "    \n",
    "    # Group by DATE, LATITUDE, and LONGITUDE, and calculate the mean of the corresponding values\n",
    "    result = df.groupby(['DATE', 'LATITUDE', 'LONGITUDE']).mean().reset_index()\n",
    "    \n",
    "    # Extract the filename without extension from the full path\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    \n",
    "    # Save the result to a new CSV file with the filename as part of the output path\n",
    "    output_file_path = f\"{filename}_atmospheric_clean.csv\"\n",
    "    result.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Results for {file} saved to {output_file_path}\")\n",
    "    # Optionally, you can remove the original file after saving the result\n",
    "    os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define columns with suspiciously high values\n",
    "suspicious_columns = ['TMP', 'DEW', 'SLP', 'DIR', 'SPD']\n",
    "\n",
    "# Define unusually high values for each column\n",
    "unusually_large_values = {'TMP': 999.9, 'DEW': 999.9, 'SLP': 99999.0, 'DIR': 999.0, 'SPD': 9999.0}\n",
    "\n",
    "# Create the IterativeImputer\n",
    "imputer = IterativeImputer()\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob('./*.csv')\n",
    "\n",
    "for file in csv_files:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Convert 'DATE' column to datetime format\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "    # Replace unusually large values with NaN\n",
    "    for column in suspicious_columns:\n",
    "        df[column].replace(unusually_large_values[column], float('NaN'), inplace=True)\n",
    "\n",
    "    # Replace out-of-range wind direction values with NaN\n",
    "    df['DIR'] = df['DIR'].where(df['DIR'].between(0, 360), float('NaN'))\n",
    "\n",
    "    # Perform imputation on each column separately\n",
    "    for column in suspicious_columns:\n",
    "        df[[column]] = imputer.fit_transform(df[[column]])\n",
    "\n",
    "    # Limit imputed wind direction values to the range 0-360\n",
    "    df['DIR'] = np.clip(df['DIR'], 0, 360)\n",
    "\n",
    "    # Save the imputed dataframe to a new CSV file\n",
    "    df.to_csv(os.path.join('.', os.path.basename(file)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metstat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
