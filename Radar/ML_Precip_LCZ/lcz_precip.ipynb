{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Longitude   Latitude  Core Area\n",
       " 0  -95.66735  28.891169       9.00\n",
       " 1  -95.68225  28.901718       8.00\n",
       " 2  -95.69984  28.910925       5.75\n",
       " 3  -95.71833  28.922235       5.00\n",
       " 4  -95.74094  28.937017       4.25,\n",
       "    Longitude   Latitude  Precipitation\n",
       " 0 -97.429273  29.487136            6.0\n",
       " 1 -97.429028  29.523018            7.3\n",
       " 2 -97.428804  29.451254            5.2\n",
       " 3 -97.428066  29.558892            3.6\n",
       " 4 -97.427620  29.415385           14.3,\n",
       "    Station     TYPE  CA    PLAND  NP           PD     LPI     TE           ED  \\\n",
       " 0        1  openLow   0  24.5098  22  17973856209  6.5359  0.406  3316993.464   \n",
       " 1        1  openLow   0  24.5098  22  17973856209  6.5359  0.406  3316993.464   \n",
       " 2        1  openLow   0  24.5098  22  17973856209  6.5359  0.406  3316993.464   \n",
       " 3        1  openLow   0  24.5098  22  17973856209  6.5359  0.406  3316993.464   \n",
       " 4        1  openLow   0  24.5098  22  17973856209  6.5359  0.406  3316993.464   \n",
       " \n",
       "       LSI  ...  LATITUDE  LONGITUDE  ELEVATION    VIS   TMP   DEW    SLP  DIR  \\\n",
       " 0  6.2222  ...  29.51924   -95.2423       11.9   9656  28.3  24.4      0  140   \n",
       " 1  6.2222  ...  29.51924   -95.2423       11.9  16093  28.3  25.0      0  140   \n",
       " 2  6.2222  ...  29.51924   -95.2423       11.9  16093  28.9  23.9  10126  140   \n",
       " 3  6.2222  ...  29.51924   -95.2423       11.9  16093  28.3  23.9  10128  130   \n",
       " 4  6.2222  ...  29.51924   -95.2423       11.9  16093  27.8  23.9  10130  130   \n",
       " \n",
       "    SPD  HEIGHT_AGL  \n",
       " 0   57         762  \n",
       " 1   46       22000  \n",
       " 2   41       22000  \n",
       " 3   51       22000  \n",
       " 4   41       22000  \n",
       " \n",
       " [5 rows x 155 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the files\n",
    "core_area = pd.read_csv(\"./data/core_area.csv\")\n",
    "grouped_precip = pd.read_csv(\"./data/grouped_precip.csv\")\n",
    "lcz = pd.read_csv(\"./data/lcz.csv\")\n",
    "\n",
    "# Remove leading and trailing spaces from column names of the LCZ\n",
    "lcz.columns = lcz.columns.str.strip()\n",
    "lcz = lcz.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "core_area.head(), grouped_precip.head(),lcz.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We discover important variables from the LCZ dataset using RandomForest to calculate feature importance. The targt variable would be both the precipitation and updraft, given that we want to understand the impact of the LCZ features on both of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['LONGITUDE', 'LATITUDE'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m correlation\n\u001b[0;32m     52\u001b[0m \u001b[39m# Apply the function to all stations in the LCZ data\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m correlations \u001b[39m=\u001b[39m lcz\u001b[39m.\u001b[39;49mapply(calculate_correlation_for_station, args\u001b[39m=\u001b[39;49m(core_area, grouped_precip, \u001b[39m5\u001b[39;49m), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     55\u001b[0m \u001b[39m# Add the correlations as a new column in the LCZ data\u001b[39;00m\n\u001b[0;32m     56\u001b[0m lcz[\u001b[39m'\u001b[39m\u001b[39mCorrelation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m correlations\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\apply.py:142\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m, in \u001b[0;36mcalculate_correlation_for_station\u001b[1;34m(station, core_area, grouped_precip, k)\u001b[0m\n\u001b[0;32m     37\u001b[0m nn\u001b[39m.\u001b[39mfit(core_area[[\u001b[39m\"\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[0;32m     39\u001b[0m \u001b[39m# Find the k nearest points in the core_area data for the station\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m station_coordinates \u001b[39m=\u001b[39m station[[\u001b[39m\"\u001b[39;49m\u001b[39mLONGITUDE\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mLATITUDE\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m distances, indices \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mkneighbors(station_coordinates)\n\u001b[0;32m     43\u001b[0m \u001b[39m# Get the core_area and grouped_precip values for the nearest points\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m   1005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\series.py:1047\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[key]\n\u001b[0;32m   1046\u001b[0m \u001b[39m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[key]\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omitu\\anaconda3\\envs\\metstat\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['LONGITUDE', 'LATITUDE'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "core_area = pd.read_csv(\"./data/core_area.csv\")\n",
    "grouped_precip = pd.read_csv(\"./data/grouped_precip.csv\")\n",
    "lcz = pd.read_csv(\"./data/combined_data.csv\")\n",
    "\n",
    "# Remove leading and trailing spaces from column names of the LCZ\n",
    "lcz.columns = lcz.columns.str.strip()\n",
    "lcz = lcz.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Encode the 'TYPE' feature in the LCZ data\n",
    "le = LabelEncoder()\n",
    "lcz_numerical = le.fit_transform(lcz['TYPE'])\n",
    "\n",
    "# Add the 'LCZ' variable to the LCZ data and drop the 'TYPE' feature\n",
    "lcz['LCZ'] = lcz_numerical\n",
    "lcz = lcz.drop(columns=['TYPE'])\n",
    "\n",
    "# Function to append a suffix to duplicate column names\n",
    "def rename_duplicates(old):\n",
    "    seen = {}\n",
    "    for x in old:\n",
    "        if x in seen:\n",
    "            seen[x] += 1\n",
    "            yield \"%s_%d\" % (x, seen[x])\n",
    "        else:\n",
    "            seen[x] = 0\n",
    "            yield x\n",
    "\n",
    "# Apply the function to the column names in the LCZ data\n",
    "lcz.columns = list(rename_duplicates(lcz.columns))\n",
    "\n",
    "# Function to calculate correlation for each station\n",
    "def calculate_correlation_for_station(station, core_area, grouped_precip, k=5):\n",
    "    # Create a NearestNeighbors model\n",
    "    nn = NearestNeighbors(n_neighbors=k)\n",
    "\n",
    "    # Fit the model to the core_area data\n",
    "    nn.fit(core_area[[\"Longitude\", \"Latitude\"]])\n",
    "\n",
    "    # Find the k nearest points in the core_area data for the station\n",
    "    station_coordinates = station[[\"LONGITUDE\", \"LATITUDE\"]].values.reshape(1, -1)\n",
    "    distances, indices = nn.kneighbors(station_coordinates)\n",
    "\n",
    "    # Get the core_area and grouped_precip values for the nearest points\n",
    "    core_area_values = core_area.iloc[indices[0]][\"Core Area\"]\n",
    "    grouped_precip_values = grouped_precip.iloc[indices[0]][\"Precipitation\"]\n",
    "\n",
    "    # Calculate the correlation between the core_area and grouped_precip values\n",
    "    correlation, _ = pearsonr(core_area_values, grouped_precip_values)\n",
    "\n",
    "    return correlation\n",
    "\n",
    "# Apply the function to all stations in the LCZ data\n",
    "correlations = lcz.apply(calculate_correlation_for_station, args=(core_area, grouped_precip, 5), axis=1)\n",
    "\n",
    "# Add the correlations as a new column in the LCZ data\n",
    "lcz['Correlation'] = correlations\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numerical_features = lcz.select_dtypes(include=[np.number]).columns.drop('Correlation')\n",
    "categorical_features = ['LCZ']\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocessing the LCZ data\n",
    "lcz_preprocessed = preprocessor.fit_transform(lcz)\n",
    "\n",
    "# Fit a RandomForest model to the preprocessed LCZ data\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(lcz_preprocessed, lcz['Correlation'])\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Get the names of the features from the preprocessor\n",
    "feature_names = preprocessor.transformers_[0][1].get_feature_names_out(numerical_features)\n",
    "feature_names = np.concatenate([feature_names, preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)])\n",
    "\n",
    "# Create a DataFrame that contains the feature importances\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "\n",
    "# Sort the DataFrame by the importances, in descending order\n",
    "feature_importances_sorted = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "feature_importances_sorted.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metstat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
